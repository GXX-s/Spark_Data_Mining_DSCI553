
[Executed at: Fri Nov 5 23:47:56 PDT 2021]

==================================================
Task 1 (python) runtime (ms), 195817
Task 1: 2.0 out of 2
==================================================
Task 2 (python) runtime (ms), 15880
Task 2.1: 2.0 out of 2
Task 2.2: 1.5 out of 3
==================================================
task1.scala not found
Task 1(Scala) runtime (ms), 5
Task 1 Scala: 0.0
==================================================
task2.scala not found
Task 2 (Scala) runtime (ms), 1
Task 2.1 Scala:  0.0
Task 2.2 Scala:  0.0
==================================================

21/11/05 23:44:00 WARN Utils: Your hostname, ip-172-31-27-66 resolves to a loopback address: 127.0.0.1; using 172.31.27.66 instead (on interface ens5)
21/11/05 23:44:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
:: loading settings :: url = jar:file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/ccc_v1_g_83254_33254/.ivy2/cache
The jars for the packages stored in: /home/ccc_v1_g_83254_33254/.ivy2/jars
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-e11e99ab-f2b5-433a-8666-3c16b3d27562;1.0
	confs: [default]
	found graphframes#graphframes;0.8.2-spark3.1-s_2.12 in spark-packages
	found org.slf4j#slf4j-api;1.7.16 in central
:: resolution report :: resolve 550ms :: artifacts dl 22ms
	:: modules in use:
	graphframes#graphframes;0.8.2-spark3.1-s_2.12 from spark-packages in [default]
	org.slf4j#slf4j-api;1.7.16 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-e11e99ab-f2b5-433a-8666-3c16b3d27562
	confs: [default]
	0 artifacts copied, 2 already retrieved (0kB/13ms)
21/11/05 23:44:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/05 23:44:05 INFO SparkContext: Running Spark version 3.1.2
21/11/05 23:44:05 INFO ResourceUtils: ==============================================================
21/11/05 23:44:05 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/05 23:44:05 INFO ResourceUtils: ==============================================================
21/11/05 23:44:05 INFO SparkContext: Submitted application: task1
21/11/05 23:44:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/05 23:44:05 INFO ResourceProfile: Limiting resource is cpu
21/11/05 23:44:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/05 23:44:05 INFO SecurityManager: Changing view acls to: ccc_v1_g_83254_33254
21/11/05 23:44:05 INFO SecurityManager: Changing modify acls to: ccc_v1_g_83254_33254
21/11/05 23:44:05 INFO SecurityManager: Changing view acls groups to: 
21/11/05 23:44:05 INFO SecurityManager: Changing modify acls groups to: 
21/11/05 23:44:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_83254_33254); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_83254_33254); groups with modify permissions: Set()
21/11/05 23:44:05 INFO Utils: Successfully started service 'sparkDriver' on port 34517.
21/11/05 23:44:05 INFO SparkEnv: Registering MapOutputTracker
21/11/05 23:44:05 INFO SparkEnv: Registering BlockManagerMaster
21/11/05 23:44:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/05 23:44:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/05 23:44:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/05 23:44:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4a1aa8cf-e4a1-4967-a1ca-f6d3ec3c0e7f
21/11/05 23:44:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
21/11/05 23:44:06 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/05 23:44:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/11/05 23:44:06 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/11/05 23:44:06 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.27.66:4041
21/11/05 23:44:06 INFO SparkContext: Added JAR file:///home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar at spark://172.31.27.66:34517/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1636181045123
21/11/05 23:44:06 INFO SparkContext: Added JAR file:///home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://172.31.27.66:34517/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1636181045123
21/11/05 23:44:06 INFO SparkContext: Added file file:///home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar at file:///home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1636181045123
21/11/05 23:44:06 INFO Utils: Copying /home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
21/11/05 23:44:06 INFO SparkContext: Added file file:///home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at file:///home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1636181045123
21/11/05 23:44:06 INFO Utils: Copying /home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/org.slf4j_slf4j-api-1.7.16.jar
21/11/05 23:44:07 INFO Executor: Starting executor ID driver on host 172.31.27.66
21/11/05 23:44:07 INFO Executor: Fetching file:///home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1636181045123
21/11/05 23:44:07 INFO Utils: /home/ccc_v1_g_83254_33254/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar has been previously copied to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
21/11/05 23:44:07 INFO Executor: Fetching file:///home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1636181045123
21/11/05 23:44:07 INFO Utils: /home/ccc_v1_g_83254_33254/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar has been previously copied to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/org.slf4j_slf4j-api-1.7.16.jar
21/11/05 23:44:07 INFO Executor: Fetching spark://172.31.27.66:34517/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1636181045123
21/11/05 23:44:07 INFO TransportClientFactory: Successfully created connection to /172.31.27.66:34517 after 88 ms (0 ms spent in bootstraps)
21/11/05 23:44:07 INFO Utils: Fetching spark://172.31.27.66:34517/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/fetchFileTemp1411692219569331646.tmp
21/11/05 23:44:07 INFO Utils: /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/fetchFileTemp1411692219569331646.tmp has been previously copied to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/org.slf4j_slf4j-api-1.7.16.jar
21/11/05 23:44:07 INFO Executor: Adding file:/tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/org.slf4j_slf4j-api-1.7.16.jar to class loader
21/11/05 23:44:07 INFO Executor: Fetching spark://172.31.27.66:34517/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar with timestamp 1636181045123
21/11/05 23:44:07 INFO Utils: Fetching spark://172.31.27.66:34517/jars/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/fetchFileTemp17175535727519741926.tmp
21/11/05 23:44:07 INFO Utils: /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/fetchFileTemp17175535727519741926.tmp has been previously copied to /tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar
21/11/05 23:44:07 INFO Executor: Adding file:/tmp/spark-88d09b80-7c38-4808-9553-bba8a496f46c/userFiles-94d11d1e-0c7e-4e44-b1d4-5aed27aca626/graphframes_graphframes-0.8.2-spark3.1-s_2.12.jar to class loader
21/11/05 23:44:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36967.
21/11/05 23:44:07 INFO NettyBlockTransferService: Server created on 172.31.27.66:36967
21/11/05 23:44:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/05 23:44:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.27.66, 36967, None)
21/11/05 23:44:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.27.66:36967 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.27.66, 36967, None)
21/11/05 23:44:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.27.66, 36967, None)
21/11/05 23:44:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.27.66, 36967, None)
Duration:  187.0685098171234
21/11/05 23:47:14 WARN Utils: Your hostname, ip-172-31-27-66 resolves to a loopback address: 127.0.0.1; using 172.31.27.66 instead (on interface ens5)
21/11/05 23:47:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
21/11/05 23:47:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/05 23:47:14 INFO SparkContext: Running Spark version 3.1.2
21/11/05 23:47:15 INFO ResourceUtils: ==============================================================
21/11/05 23:47:15 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/05 23:47:15 INFO ResourceUtils: ==============================================================
21/11/05 23:47:15 INFO SparkContext: Submitted application: task2
21/11/05 23:47:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/05 23:47:15 INFO ResourceProfile: Limiting resource is cpu
21/11/05 23:47:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/05 23:47:15 INFO SecurityManager: Changing view acls to: ccc_v1_g_83254_33254
21/11/05 23:47:15 INFO SecurityManager: Changing modify acls to: ccc_v1_g_83254_33254
21/11/05 23:47:15 INFO SecurityManager: Changing view acls groups to: 
21/11/05 23:47:15 INFO SecurityManager: Changing modify acls groups to: 
21/11/05 23:47:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_83254_33254); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_83254_33254); groups with modify permissions: Set()
21/11/05 23:47:15 INFO Utils: Successfully started service 'sparkDriver' on port 33179.
21/11/05 23:47:15 INFO SparkEnv: Registering MapOutputTracker
21/11/05 23:47:15 INFO SparkEnv: Registering BlockManagerMaster
21/11/05 23:47:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/05 23:47:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/05 23:47:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/05 23:47:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4ce831c6-0405-4878-b904-11312c989539
21/11/05 23:47:15 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
21/11/05 23:47:15 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/05 23:47:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/05 23:47:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.27.66:4040
21/11/05 23:47:15 INFO Executor: Starting executor ID driver on host 172.31.27.66
21/11/05 23:47:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46695.
21/11/05 23:47:15 INFO NettyBlockTransferService: Server created on 172.31.27.66:46695
21/11/05 23:47:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/05 23:47:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.27.66, 46695, None)
21/11/05 23:47:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.27.66:46695 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.27.66, 46695, None)
21/11/05 23:47:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.27.66, 46695, None)
21/11/05 23:47:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.27.66, 46695, None)
Duration:  13.42647409439087
21/11/05 23:47:30 WARN Utils: Your hostname, ip-172-31-27-66 resolves to a loopback address: 127.0.0.1; using 172.31.27.66 instead (on interface ens5)
21/11/05 23:47:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
21/11/05 23:47:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/11/05 23:47:31 INFO SparkContext: Running Spark version 3.1.2
21/11/05 23:47:31 INFO ResourceUtils: ==============================================================
21/11/05 23:47:31 INFO ResourceUtils: No custom resources configured for spark.driver.
21/11/05 23:47:31 INFO ResourceUtils: ==============================================================
21/11/05 23:47:31 INFO SparkContext: Submitted application: task2
21/11/05 23:47:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/11/05 23:47:31 INFO ResourceProfile: Limiting resource is cpu
21/11/05 23:47:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/11/05 23:47:31 INFO SecurityManager: Changing view acls to: ccc_v1_g_83254_33254
21/11/05 23:47:31 INFO SecurityManager: Changing modify acls to: ccc_v1_g_83254_33254
21/11/05 23:47:31 INFO SecurityManager: Changing view acls groups to: 
21/11/05 23:47:31 INFO SecurityManager: Changing modify acls groups to: 
21/11/05 23:47:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_83254_33254); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_83254_33254); groups with modify permissions: Set()
21/11/05 23:47:31 INFO Utils: Successfully started service 'sparkDriver' on port 43959.
21/11/05 23:47:31 INFO SparkEnv: Registering MapOutputTracker
21/11/05 23:47:31 INFO SparkEnv: Registering BlockManagerMaster
21/11/05 23:47:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/11/05 23:47:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/11/05 23:47:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/11/05 23:47:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a46b2ed4-43ca-48cc-8b3b-775e0c950c05
21/11/05 23:47:31 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
21/11/05 23:47:31 INFO SparkEnv: Registering OutputCommitCoordinator
21/11/05 23:47:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/11/05 23:47:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.27.66:4040
21/11/05 23:47:31 INFO Executor: Starting executor ID driver on host 172.31.27.66
21/11/05 23:47:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39171.
21/11/05 23:47:31 INFO NettyBlockTransferService: Server created on 172.31.27.66:39171
21/11/05 23:47:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/11/05 23:47:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.27.66, 39171, None)
21/11/05 23:47:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.27.66:39171 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.27.66, 39171, None)
21/11/05 23:47:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.27.66, 39171, None)
21/11/05 23:47:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.27.66, 39171, None)
Duration:  16.792693853378296
